# CMPE-297-Transformers-and-finetuning-with-LLMs

**Question 2: 
Transformers and finetuning with LLMs**

**a) Implement nanogpt from scratch using your own code in pytorch, tensorflow and jax**

Text generation with NanoGPT using **Pytorch:**

**Colab link:** https://colab.research.google.com/drive/1FHUaPIWfqLF7CPwNv3ywMFkgcuGrzo8f?usp=sharing

Text generation with NanoGPT using **TensorFlow:**

**Colab link:** https://colab.research.google.com/drive/1umJMAPLqd7vXa0wzo9PC0_A1_3ToCAiF?usp=sharing

Text generation with NanoGPT using **JAX:**

**Colab link:** https://colab.research.google.com/drive/1_wA8DdT52i1KuDJ8D2DqEv3qVNQS409O?usp=sharing

**b) Implement "textbooks are all you need"**

Used the existing model that is finetuned with python dataset to finetune the model. 

**Colab link:** https://colab.research.google.com/drive/1qp31a2NE0WTSzV_QdjV3xRCmYOC_EJGg?usp=sharing

