# CMPE-297-Transformers-and-finetuning-with-LLMs

**Question 2: 
Transformers and finetuning with LLMs**

**a) Implement nanogpt from scratch using your own code in pytorch, tensorflow and jax**

Text generation with NanoGPT using **Pytorch:**

**Colab link:** https://colab.research.google.com/drive/1FHUaPIWfqLF7CPwNv3ywMFkgcuGrzo8f?usp=sharing

Text generation with NanoGPT using **TensorFlow:**

**Colab link:** https://colab.research.google.com/drive/1umJMAPLqd7vXa0wzo9PC0_A1_3ToCAiF?usp=sharing

Text generation with NanoGPT using **JAX:**

**Colab link:** https://colab.research.google.com/drive/1_wA8DdT52i1KuDJ8D2DqEv3qVNQS409O?usp=sharing

**Medium Article:** https://medium.com/@abdulvahed.shaik/text-generation-withtransformers-86a0adde2fad

**Youtube Video Link:** https://youtu.be/2eDW4qVqQyU

**b) Implement "textbooks are all you need"**

Used the existing model that is finetuned with python dataset to finetune the model. 

**Colab link:** https://colab.research.google.com/drive/1qp31a2NE0WTSzV_QdjV3xRCmYOC_EJGg?usp=sharing

**screenshot of the output:**

![Alt Text](https://github.com/vahedshaik/CMPE-297-Transformers-and-finetuning-with-LLMs/blob/4ada7d15d572f60f184bab0c552e72c331752203/Screen%20Shot%202023-10-23%20at%2011.34.55%20PM.png)


